{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Финальный проект"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый высокий precision@5 удалось получить:\n",
    "\n",
    "    - упростив функцию prefilter_items - берем топ n самых популярных товаров и убираем остальные фильтры;\n",
    "    - если взять 5000 самых популярных товаров;\n",
    "    - при bm25_weight с параметрами K1=3, B=0.3;\n",
    "    - модель первого уровня - own recommendtions + top-popular;\n",
    "    - при отборе 100 кандидатов моделью первого уровня;\n",
    "    - при добавлении новых признаков в модель второго уровня;\n",
    "    - LightAutoML улучшает качество рекомендаций (по сравнению с LightGBM моделью);\n",
    "    - эксперименты с различными весами в user-item матрице не принесли интересных результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# План\n",
    "\n",
    "    1. Двухуровневая модель для покупателей, когда нам известна информация о предыдущих покупках\n",
    "        a) Выбираем модель первого уровня\n",
    "        b) Модель второго уровня\n",
    "            - LightGBM модель\n",
    "            - LightAutoML модель\n",
    "     2. Модель для новых покупателей, о покупках которых у нас нет информации\n",
    "     3. Объединение рекомендаций, полученных на этапе 1 и 2\n",
    "     4. Валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit import als\n",
    "\n",
    "# Модели второго уровня\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.tasks.common_metric import mean_quantile_error\n",
    "\n",
    "# Написанные нами функции\n",
    "from src.metrics import precision_at_k, recall_at_k\n",
    "from src.utils import prefilter_items\n",
    "from src.recommenders import MainRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../retail_train.csv')\n",
    "item_features = pd.read_csv('../product.csv')\n",
    "user_features = pd.read_csv('../hh_demographic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column processing\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1004906</td>\n",
       "      <td>1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1033142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "0     2375  26984851472    1  1004906         1         1.39       364   \n",
       "1     2375  26984851472    1  1033142         1         0.82       364   \n",
       "\n",
       "   retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "0         -0.6        1631        1          0.0                0.0  \n",
       "1          0.0        1631        1          0.0                0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Схема обучения и валидации\n",
    "# -- давние покупки -- | -- 6 недель -- | -- 3 недель -- \n",
    "val_lvl_1_size_weeks = 6\n",
    "val_lvl_2_size_weeks = 3\n",
    "\n",
    "data_train_lvl_1 = data[data['week_no'] < data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)]\n",
    "data_val_lvl_1 = data[(data['week_no'] >= data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)) &\n",
    "                      (data['week_no'] < data['week_no'].max() - (val_lvl_2_size_weeks))]\n",
    "\n",
    "data_train_lvl_2 = data_val_lvl_1.copy()\n",
    "data_val_lvl_2 = data[data['week_no'] >= data['week_no'].max() - val_lvl_2_size_weeks]\n",
    "\n",
    "data_train_lvl_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadejdaberzina/Documents/Geekbrains_New/Chetvertaya_chetvert/recsys_final_project/final_project/src/utils.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['price'] = data['sales_value'] / (np.maximum(data['quantity'], 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decreased # items from 83685 to 5001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadejdaberzina/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "# упростим функцию prefilter_items и возьмем топ n самых популярных товаров, убрав остальные фильтры\n",
    "\n",
    "n_items_before = data_train_lvl_1['item_id'].nunique()\n",
    "\n",
    "data_train_lvl_1 = prefilter_items(data_train_lvl_1, item_features=item_features, take_n_popular=5000)\n",
    "\n",
    "n_items_after = data_train_lvl_1['item_id'].nunique()\n",
    "print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Двухуровневая модель для покупателей, когда нам известна информация об их предыдущих покупках"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с юзеров, по которым у нас уже есть информацию из data train.\n",
    "\n",
    "Для новых юзеров построим модель на следующем этапе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Выбираем модель первого уровня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "babeadd2444c4062ab7a22334538a7f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c162beba72e84d5399233b1c70161351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274ad78ae9d747108ea34594e4a1d9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#обучаем модель первого уровня на data train level 1\n",
    "recommender = MainRecommender(data_train_lvl_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем dataframe, куда будем сохранять кандидатов, сгенерированных моделей первого уровня\n",
    "result_lvl_1 = data_val_lvl_1.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result_lvl_1.columns=['user_id', 'actual']\n",
    "\n",
    "\n",
    "# отбираем юзеров, по которым у нас есть информация из data train\n",
    "users_lvl_1 = pd.DataFrame(data_val_lvl_1['user_id'].unique())\n",
    "users_lvl_1.columns = ['user_id']\n",
    "\n",
    "train_users = data_train_lvl_1['user_id'].unique()\n",
    "users_lvl_1 = users_lvl_1[users_lvl_1['user_id'].isin(train_users)]\n",
    "\n",
    "\n",
    "# включаем в результирующий dataframe только отобранных юзеров\n",
    "result_lvl_1 = users_lvl_1.merge(result_lvl_1, on=['user_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем кандидатов\n",
    "k = 100\n",
    "\n",
    "result_lvl_1['als'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_als_recommendations(x, N=k))\n",
    "result_lvl_1['own'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=k))\n",
    "result_lvl_1['similar_items'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_similar_items_recommendation(x, N=k))\n",
    "result_lvl_1['similar_users'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_similar_users_recommendation(x, N=k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(data, metric, k=100):\n",
    "    \n",
    "    for column in data.columns[2:]:\n",
    "        \n",
    "        yield column, data.apply(lambda row: metric(row[column], row['actual'], k=k), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('own', 0.21068430151403514),\n",
       " ('als', 0.15145427295287625),\n",
       " ('similar_items', 0.09212067843290002),\n",
       " ('similar_users', 0.08442621972412903)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(calc_metrics(result_lvl_1, recall_at_k), key=lambda recall_at_k: recall_at_k[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('own', 0.380213655364611),\n",
       " ('als', 0.2045517882025048),\n",
       " ('similar_users', 0.12679981421272488),\n",
       " ('similar_items', 0.09391546679052427)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(calc_metrics(result_lvl_1, precision_at_k, k=5), key=lambda precision_at_k: precision_at_k[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Own recommendtions + top-popular дают наилучший recall при отборе 100 кандидатов, а также наилучший presion@5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Модель второго уровня"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - LightGBM модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала протестируем различные параметры на LightGBM модели, чтобы расчеты занимали меньше времени.\n",
    "Следующим этапом применим LightAutoML модель, сохранив параметры, при которых LightGBM покажет наилучший результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Обучим модель второго уровня на data_train_lvl_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отберем юзеров, по которым у нас есть информация из data train\n",
    "users_lvl_2 = pd.DataFrame(data_train_lvl_2['user_id'].unique())\n",
    "users_lvl_2.columns = ['user_id']\n",
    "\n",
    "train_users = data_train_lvl_1['user_id'].unique()\n",
    "users_lvl_2 = users_lvl_2[users_lvl_2['user_id'].isin(train_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем кандидатов\n",
    "users_lvl_2['candidates'] = users_lvl_2['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем dataframe для модели второго уровня с флагом купил / не купил\n",
    "s = users_lvl_2.apply(lambda x: pd.Series(x['candidates']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'item_id'\n",
    "\n",
    "users_lvl_2 = users_lvl_2.drop('candidates', axis=1).join(s)\n",
    "\n",
    "targets_lvl_2 = data_train_lvl_2[['user_id', 'item_id']].copy()\n",
    "targets_lvl_2['target'] = 1  # тут только покупки \n",
    "\n",
    "targets_lvl_2 = users_lvl_2.merge(targets_lvl_2, on=['user_id', 'item_id'], how='left')\n",
    "\n",
    "targets_lvl_2['target'].fillna(0, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим имеющиеся данные по пользователям и товарам\n",
    "targets_lvl_2 = targets_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "targets_lvl_2 = targets_lvl_2.merge(user_features, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем новые признаки\n",
    "# средний чек\n",
    "average_receipt = data_train_lvl_2.groupby(['user_id', 'basket_id'])['sales_value'].sum().reset_index()\n",
    "average_receipt = average_receipt.groupby('user_id')['sales_value'].mean().reset_index()\n",
    "average_receipt.columns=['user_id', 'average_receipt']\n",
    "targets_lvl_2 = targets_lvl_2.merge(average_receipt, how='left', on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем новые признаки\n",
    "# кол-во покупок в каждой категории\n",
    "purchases_per_category = data_train_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "purchases_per_category = purchases_per_category.groupby(['user_id', 'commodity_desc'])['quantity'].sum().reset_index() # кол-во покупок в каждой категории\n",
    "purchases_per_category.columns=['user_id', 'commodity_desc', 'purchases_per_category']\n",
    "targets_lvl_2 = targets_lvl_2.merge(purchases_per_category, how='left', on=['user_id', 'commodity_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем новые признаки\n",
    "# кол-во покупок в каждой под-категории\n",
    "purchases_per_sub_category = data_train_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "purchases_per_sub_category = purchases_per_sub_category.groupby(['user_id', 'sub_commodity_desc'])['quantity'].sum().reset_index() # кол-во покупок в каждой категории\n",
    "purchases_per_sub_category.columns=['user_id', 'sub_commodity_desc', 'purchases_per_sub_category']\n",
    "targets_lvl_2 = targets_lvl_2.merge(purchases_per_sub_category, how='left', on=['user_id', 'sub_commodity_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем новые признаки\n",
    "# покупки в каждой под-категории в денежном эквиваленте\n",
    "value_per_sub_category = data_train_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "value_per_sub_category = value_per_sub_category.groupby(['user_id', 'sub_commodity_desc'])['sales_value'].sum().reset_index() # кол-во покупок в каждой категории\n",
    "value_per_sub_category.columns=['user_id', 'sub_commodity_desc', 'value_per_sub_category']\n",
    "targets_lvl_2 = targets_lvl_2.merge(value_per_sub_category, how='left', on=['user_id', 'sub_commodity_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем новые признаки\n",
    "# среднее количество покупок в неделю для каждого товара\n",
    "purchases_per_week = data_train_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "purchases_per_week = purchases_per_week.groupby(['item_id', 'week_no'])['quantity'].sum().reset_index()\n",
    "purchases_per_week = purchases_per_week.groupby('item_id')['quantity'].mean().reset_index()\n",
    "purchases_per_week.columns=['item_id', 'purchases_per_week']\n",
    "targets_lvl_2 = targets_lvl_2.merge(purchases_per_week, how='left', on='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# готовим X_train и y_train\n",
    "X_train = targets_lvl_2.drop('target', axis=1)\n",
    "y_train = targets_lvl_2[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = X_train.columns[2:15].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[cat_feats] = X_train[cat_feats].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadejdaberzina/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/nadejdaberzina/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/nadejdaberzina/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:863: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt',\n",
       "               categorical_column=['manufacturer', 'department', 'brand',\n",
       "                                   'commodity_desc', 'sub_commodity_desc',\n",
       "                                   'curr_size_of_product', 'age_desc',\n",
       "                                   'marital_status_code', 'income_desc',\n",
       "                                   'homeowner_desc', 'hh_comp_desc',\n",
       "                                   'household_size_desc', 'kid_category_desc'],\n",
       "               class_weight=None, colsample_bytree=1.0, importance_type='split',\n",
       "               learning_rate=0.1, max_depth=7, min_child_samples=20,\n",
       "               min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "               n_jobs=-1, num_leaves=31, objective='binary', random_state=None,\n",
       "               reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb = LGBMClassifier(objective='binary', max_depth=7, categorical_column=cat_feats)\n",
    "lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Проверяем качество модели на data_val_lvl_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отберем юзеров, по которым у нас есть информация из data train\n",
    "users_lvl_2_val = pd.DataFrame(data_val_lvl_2['user_id'].unique())\n",
    "users_lvl_2_val.columns = ['user_id']\n",
    "\n",
    "train_users_lvl_2 = users_lvl_2['user_id'].unique()\n",
    "users_lvl_2_val = users_lvl_2_val[users_lvl_2_val['user_id'].isin(train_users_lvl_2)]\n",
    "\n",
    "\n",
    "# создаем dataframe, куда будем сохранять рекомендации\n",
    "result_lvl_2 = data_val_lvl_2.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result_lvl_2.columns=['user_id', 'actual']\n",
    "\n",
    "result_lvl_2 = result_lvl_2[result_lvl_2['user_id'].isin(targets_lvl_2.user_id.unique())]\n",
    "\n",
    "result_lvl_2 = users_lvl_2_val.merge(result_lvl_2, how='left', on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценим качество для модели первого уровня\n",
    "result_lvl_2['own'] = result_lvl_2['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем кандидатов\n",
    "users_lvl_2_val['candidates'] = users_lvl_2_val['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем dataframe для модели второго уровня с флагом купил / не купил\n",
    "s = users_lvl_2_val.apply(lambda x: pd.Series(x['candidates']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'item_id'\n",
    "\n",
    "users_lvl_2_val = users_lvl_2_val.drop('candidates', axis=1).join(s)\n",
    "\n",
    "targets_lvl_2_val = data_val_lvl_2[['user_id', 'item_id']].copy()\n",
    "\n",
    "targets_lvl_2_val = users_lvl_2_val.merge(targets_lvl_2_val, on=['user_id', 'item_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим имеющиеся данные по пользователям и товарам\n",
    "targets_lvl_2_val = targets_lvl_2_val.merge(item_features, on='item_id', how='left')\n",
    "targets_lvl_2_val = targets_lvl_2_val.merge(user_features, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем новые признаки\n",
    "# средний чек\n",
    "average_receipt = data_val_lvl_2.groupby(['user_id', 'basket_id'])['sales_value'].sum().reset_index()\n",
    "average_receipt = average_receipt.groupby('user_id')['sales_value'].mean().reset_index()\n",
    "average_receipt.columns=['user_id', 'average_receipt']\n",
    "targets_lvl_2_val = targets_lvl_2_val.merge(average_receipt, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем новые признаки\n",
    "# кол-во покупок в каждой категории\n",
    "purchases_per_category = data_val_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "purchases_per_category = purchases_per_category.groupby(['user_id', 'commodity_desc'])['quantity'].sum().reset_index() # кол-во покупок в каждой категории\n",
    "purchases_per_category.columns=['user_id','commodity_desc', 'purchases_per_category']\n",
    "targets_lvl_2_val = targets_lvl_2_val.merge(purchases_per_category, how='left', on=['user_id', 'commodity_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем новые признаки\n",
    "# кол-во покупок в каждой под-категории\n",
    "purchases_per_sub_category = data_val_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "purchases_per_sub_category = purchases_per_sub_category.groupby(['user_id', 'sub_commodity_desc'])['quantity'].sum().reset_index() # кол-во покупок в каждой категории\n",
    "purchases_per_sub_category.columns=['user_id','sub_commodity_desc', 'purchases_per_sub_category']\n",
    "targets_lvl_2_val = targets_lvl_2_val.merge(purchases_per_sub_category, how='left', on=['user_id', 'sub_commodity_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем новые признаки\n",
    "# покупки в каждой под-категории в денежном эквиваленте\n",
    "value_per_sub_category = data_val_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "value_per_sub_category = value_per_sub_category.groupby(['user_id', 'sub_commodity_desc'])['sales_value'].sum().reset_index() # кол-во покупок в каждой категории\n",
    "value_per_sub_category.columns=['user_id','sub_commodity_desc', 'value_per_sub_category']\n",
    "targets_lvl_2_val = targets_lvl_2_val.merge(value_per_sub_category, how='left', on=['user_id', 'sub_commodity_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем новые признаки\n",
    "# среднее количество покупок в неделю для каждого товара\n",
    "purchases_per_week = data_val_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "purchases_per_week = purchases_per_week.groupby(['item_id', 'week_no'])['quantity'].sum().reset_index()\n",
    "purchases_per_week = purchases_per_week.groupby('item_id')['quantity'].mean().reset_index()\n",
    "purchases_per_week.columns=['item_id', 'purchases_per_week']\n",
    "targets_lvl_2_val = targets_lvl_2_val.merge(purchases_per_week, how='left', on='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# готовим данные\n",
    "cat_feats = targets_lvl_2_val.columns[2:15].tolist()\n",
    "targets_lvl_2_val[cat_feats] = targets_lvl_2_val[cat_feats].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = lgb.predict_proba(targets_lvl_2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lgbm', 0.618485639686683), ('own', 0.3427676240208894)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создаем dataframe с предсказаниями и считаем целевую метрику для модели первого уровня и модели \n",
    "\n",
    "val_preds = val_preds[:, 1]\n",
    "\n",
    "result_val = targets_lvl_2_val\n",
    "result_val['preds'] = val_preds\n",
    "\n",
    "result_val = result_val.groupby(['user_id', 'item_id'])['preds'].mean().reset_index()\n",
    "result_val = result_val.groupby('user_id').apply(lambda x: x.sort_values('preds', ascending=False).head(5).item_id.tolist())\n",
    "result_val = result_lvl_2.merge(result_val.rename('lgbm'), how='left', on='user_id')\n",
    "\n",
    "sorted(calc_metrics(result_val, precision_at_k, k=5), key=lambda precision_at_k: precision_at_k[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - LightAutoML модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = targets_lvl_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = Task('reg', loss='mse', metric='mse', greater_is_better=False)\n",
    "TIMEOUT = 300000\n",
    "N_THREADS = 4\n",
    "N_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "TARGET_NAME = 'target'\n",
    "TEST_SIZE=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = {'target': TARGET_NAME, 'drop': ['user_id, user_id']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_model = TabularAutoML(task=TASK,\n",
    "                            timeout=TIMEOUT,\n",
    "                            cpu_limit = N_THREADS,\n",
    "                            gpu_ids='all',\n",
    "                            reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n",
    "                             \n",
    "                            general_params={'use_algos': [ ['lgb_tuned', 'cb_tuned', 'cb', 'lgb'], ['lgb_tuned', 'cb'] ]},\n",
    "                             \n",
    "                            tuning_params={'max_tuning_iter': 10},\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-4074d9a9-4868-4550-a5b1-90c1c12f1011\n",
      "INFO:optuna.study.study:Trial 0 finished with value: -0.036848281857779434 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244}. Best is trial 0 with value: -0.036848281857779434.\n",
      "INFO:optuna.study.study:Trial 1 finished with value: -0.03700059369165765 and parameters: {'feature_fraction': 0.8659969709057025, 'num_leaves': 159}. Best is trial 0 with value: -0.036848281857779434.\n",
      "INFO:optuna.study.study:Trial 2 finished with value: -0.03691918204138139 and parameters: {'feature_fraction': 0.5780093202212182, 'num_leaves': 53}. Best is trial 0 with value: -0.036848281857779434.\n",
      "INFO:optuna.study.study:Trial 3 finished with value: -0.03686356827586462 and parameters: {'feature_fraction': 0.5290418060840998, 'num_leaves': 223}. Best is trial 0 with value: -0.036848281857779434.\n",
      "INFO:optuna.study.study:Trial 4 finished with value: -0.03666716858713051 and parameters: {'feature_fraction': 0.8005575058716043, 'num_leaves': 185}. Best is trial 4 with value: -0.03666716858713051.\n",
      "INFO:optuna.study.study:Trial 5 finished with value: -0.03664384555076046 and parameters: {'feature_fraction': 0.5102922471479012, 'num_leaves': 248}. Best is trial 5 with value: -0.03664384555076046.\n",
      "INFO:optuna.study.study:Trial 6 finished with value: -0.03697194019355598 and parameters: {'feature_fraction': 0.9162213204002109, 'num_leaves': 66}. Best is trial 5 with value: -0.03664384555076046.\n",
      "INFO:optuna.study.study:Trial 7 finished with value: -0.037265585546643394 and parameters: {'feature_fraction': 0.5909124836035503, 'num_leaves': 60}. Best is trial 5 with value: -0.03664384555076046.\n",
      "INFO:optuna.study.study:Trial 8 finished with value: -0.036872536675991344 and parameters: {'feature_fraction': 0.6521211214797689, 'num_leaves': 141}. Best is trial 5 with value: -0.03664384555076046.\n",
      "INFO:optuna.study.study:Trial 9 finished with value: -0.036978186245304426 and parameters: {'feature_fraction': 0.7159725093210578, 'num_leaves': 85}. Best is trial 5 with value: -0.03664384555076046.\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-89ab56c0-ab9f-4681-9da4-52410c7ca6db\n",
      "WARNING:optuna.study._optimize:Trial 0 failed because of the following error: TypeError(\"fit() got an unexpected keyword argument 'log_cout'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nadejdaberzina/opt/anaconda3/lib/python3.7/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/Users/nadejdaberzina/opt/anaconda3/lib/python3.7/site-packages/lightautoml/ml_algo/tuning/optuna.py\", line 214, in objective\n",
      "    output_dataset = _ml_algo.fit_predict(train_valid_iterator=train_valid_iterator)\n",
      "  File \"/Users/nadejdaberzina/opt/anaconda3/lib/python3.7/site-packages/lightautoml/ml_algo/base.py\", line 274, in fit_predict\n",
      "    model, pred = self.fit_predict_single_fold(train, valid)\n",
      "  File \"/Users/nadejdaberzina/opt/anaconda3/lib/python3.7/site-packages/lightautoml/ml_algo/boost_cb.py\", line 310, in fit_predict_single_fold\n",
      "    model.fit(cb_train, eval_set=cb_valid, log_cout=LoggerStream(logger, verbose_eval=100))\n",
      "TypeError: fit() got an unexpected keyword argument 'log_cout'\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-ef114272-a208-4340-b685-6302ed77f153\n",
      "INFO:optuna.study.study:Trial 0 finished with value: -0.036848281857779434 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244}. Best is trial 0 with value: -0.036848281857779434.\n",
      "INFO:optuna.study.study:Trial 1 finished with value: -0.03700059369165765 and parameters: {'feature_fraction': 0.8659969709057025, 'num_leaves': 159}. Best is trial 0 with value: -0.036848281857779434.\n",
      "INFO:optuna.study.study:Trial 2 finished with value: -0.03691918204138139 and parameters: {'feature_fraction': 0.5780093202212182, 'num_leaves': 53}. Best is trial 0 with value: -0.036848281857779434.\n",
      "INFO:optuna.study.study:Trial 3 finished with value: -0.03686356827586462 and parameters: {'feature_fraction': 0.5290418060840998, 'num_leaves': 223}. Best is trial 0 with value: -0.036848281857779434.\n",
      "INFO:optuna.study.study:Trial 4 finished with value: -0.03666716858713051 and parameters: {'feature_fraction': 0.8005575058716043, 'num_leaves': 185}. Best is trial 4 with value: -0.03666716858713051.\n",
      "INFO:optuna.study.study:Trial 5 finished with value: -0.03664384555076046 and parameters: {'feature_fraction': 0.5102922471479012, 'num_leaves': 248}. Best is trial 5 with value: -0.03664384555076046.\n",
      "INFO:optuna.study.study:Trial 6 finished with value: -0.03697194019355598 and parameters: {'feature_fraction': 0.9162213204002109, 'num_leaves': 66}. Best is trial 5 with value: -0.03664384555076046.\n",
      "INFO:optuna.study.study:Trial 7 finished with value: -0.037265585546643394 and parameters: {'feature_fraction': 0.5909124836035503, 'num_leaves': 60}. Best is trial 5 with value: -0.03664384555076046.\n",
      "INFO:optuna.study.study:Trial 8 finished with value: -0.036872536675991344 and parameters: {'feature_fraction': 0.6521211214797689, 'num_leaves': 141}. Best is trial 5 with value: -0.03664384555076046.\n"
     ]
    }
   ],
   "source": [
    "automl_pred = automl_model.fit_predict(train_data, roles = roles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_pred_val = automl_model.predict(targets_lvl_2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('automl', 0.6432375979112254), ('own', 0.3427676240208894)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = automl_pred_val.data\n",
    "targets_lvl_2_val['preds_automl'] = result\n",
    "targets_lvl_2_val['preds_automl'] = abs(targets_lvl_2_val['preds_automl'])\n",
    "\n",
    "targets_lvl_2_val = targets_lvl_2_val.groupby(['user_id', 'item_id'])['preds_automl'].mean().reset_index()\n",
    "\n",
    "result_val_automl = targets_lvl_2_val.groupby('user_id').apply(lambda x: x.sort_values('preds_automl', ascending=False).head(5).item_id.tolist())\n",
    "\n",
    "result_val_automl = result_lvl_2.merge(result_val_automl.rename('automl'), how='left', on='user_id')\n",
    "\n",
    "sorted(calc_metrics(result_val_automl, precision_at_k, k=5), key=lambda precision_at_k: precision_at_k[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Модель для новых покупателей, о покупках которых у нас нет информации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = pd.DataFrame(data_val_lvl_2['user_id'].unique())\n",
    "recs.columns = ['user_id']\n",
    "\n",
    "old_users = result_val['user_id'].unique()\n",
    "new_users = recs[~recs['user_id'].isin(old_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity_recommendation(data, n=5):\n",
    "    \n",
    "    popular = data.groupby('item_id')['sales_value'].sum().reset_index()\n",
    "    popular.sort_values('sales_value', ascending=False, inplace=True)\n",
    "    \n",
    "    recs = popular.head(n).item_id\n",
    "    return recs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadejdaberzina/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "popular_recs = popularity_recommendation(data_train_lvl_1, n=6)\n",
    "popular_recs = popular_recs[1:]\n",
    "\n",
    "new_users['recs'] = new_users['user_id'].apply(lambda x: popular_recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Объединение рекомендаций, полученных на этапе 1 и 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadejdaberzina/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4449: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "result_val_new = result_val_automl[['user_id', 'automl']]\n",
    "result_val_new.rename(columns={'automl': 'recs'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = pd.concat([result_val_new, new_users])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lvl_2 = data_val_lvl_2.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result_lvl_2.columns=['user_id', 'actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = result_lvl_2.merge(recommendations, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('recs', 0.6068560235063635)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# рассчитаем precision@5\n",
    "sorted(calc_metrics(recs, precision_at_k, k=5), key=lambda precision_at_k: precision_at_k[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = recs.drop(columns=['actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем новые тренировочный и тестовый наборы, чтобы еще раз проверить качество модели.\n",
    "\n",
    "Исключим из наших данных последние три недели, и разобьем данные на тренировочный и тестовый наборы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['week_no'] <= (data['week_no'].max() - 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1004906</td>\n",
       "      <td>1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1033142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "0     2375  26984851472    1  1004906         1         1.39       364   \n",
       "1     2375  26984851472    1  1033142         1         0.82       364   \n",
       "\n",
       "   retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "0         -0.6        1631        1          0.0                0.0  \n",
       "1          0.0        1631        1          0.0                0.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Важна схема обучения и валидации!\n",
    "# -- давние покупки -- | -- 6 недель -- | -- 3 недель -- \n",
    "\n",
    "val_lvl_1_size_weeks = 6\n",
    "val_lvl_2_size_weeks = 3\n",
    "\n",
    "data_train_lvl_1 = data[data['week_no'] < data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)]\n",
    "data_val_lvl_1 = data[(data['week_no'] >= data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)) &\n",
    "                      (data['week_no'] < data['week_no'].max() - (val_lvl_2_size_weeks))]\n",
    "\n",
    "data_train_lvl_2 = data_val_lvl_1.copy()\n",
    "data_val_lvl_2 = data[data['week_no'] >= data['week_no'].max() - val_lvl_2_size_weeks]\n",
    "\n",
    "data_train_lvl_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadejdaberzina/Documents/Geekbrains_New/Chetvertaya_chetvert/recsys_final_project/final_project/src/utils.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['price'] = data['sales_value'] / (np.maximum(data['quantity'], 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decreased # items from 82059 to 5001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadejdaberzina/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "# берем только топ n самых популярных товаров\n",
    "\n",
    "n_items_before = data_train_lvl_1['item_id'].nunique()\n",
    "\n",
    "data_train_lvl_1 = prefilter_items(data_train_lvl_1, item_features=item_features, take_n_popular=5000)\n",
    "\n",
    "n_items_after = data_train_lvl_1['item_id'].nunique()\n",
    "print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Oбучаем модель первого уровня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09665e02560417aa86042d9e90d66c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddff21c3ee545b3ada65fa060836996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3c12bbb6144325949fa43941ab375c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#обучаем модель первого уровня на data train level 1\n",
    "recommender = MainRecommender(data_train_lvl_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Генерируем кандидатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отберем юзеров, по которым у нас есть информация из data train\n",
    "users_lvl_2 = pd.DataFrame(data_train_lvl_2['user_id'].unique())\n",
    "users_lvl_2.columns = ['user_id']\n",
    "\n",
    "train_users = data_train_lvl_1['user_id'].unique()\n",
    "users_lvl_2 = users_lvl_2[users_lvl_2['user_id'].isin(train_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем кандидатов\n",
    "users_lvl_2['candidates'] = users_lvl_2['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Oбучаем модель второго уровня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем dataframe для модели второго уровня с флагом купил / не купил\n",
    "s = users_lvl_2.apply(lambda x: pd.Series(x['candidates']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'item_id'\n",
    "\n",
    "users_lvl_2 = users_lvl_2.drop('candidates', axis=1).join(s)\n",
    "\n",
    "targets_lvl_2 = data_train_lvl_2[['user_id', 'item_id']].copy()\n",
    "targets_lvl_2['target'] = 1  # тут только покупки \n",
    "\n",
    "targets_lvl_2 = users_lvl_2.merge(targets_lvl_2, on=['user_id', 'item_id'], how='left')\n",
    "\n",
    "targets_lvl_2['target'].fillna(0, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим имеющиеся данные по пользователям и товарам\n",
    "targets_lvl_2 = targets_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "targets_lvl_2 = targets_lvl_2.merge(user_features, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем новые признаки\n",
    "# средний чек\n",
    "average_receipt = data_train_lvl_2.groupby(['user_id', 'basket_id'])['sales_value'].sum().reset_index()\n",
    "average_receipt = average_receipt.groupby('user_id')['sales_value'].mean().reset_index()\n",
    "average_receipt.columns=['user_id', 'average_receipt']\n",
    "targets_lvl_2 = targets_lvl_2.merge(average_receipt, how='left', on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем новые признаки\n",
    "# кол-во покупок в каждой категории\n",
    "purchases_per_category.columns=['user_id','commodity_desc', 'purchases_per_category']\n",
    "purchases_per_category = data_train_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "purchases_per_category = purchases_per_category.groupby(['user_id', 'commodity_desc'])['quantity'].sum().reset_index()\n",
    "purchases_per_category.columns=['user_id','commodity_desc', 'purchases_per_category']\n",
    "targets_lvl_2 = targets_lvl_2.merge(purchases_per_category, how='left', on=['user_id', 'commodity_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем новые признаки\n",
    "# кол-во покупок в каждой под-категории\n",
    "purchases_per_sub_category = data_train_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "purchases_per_sub_category = purchases_per_sub_category.groupby(['user_id', 'sub_commodity_desc'])['quantity'].sum().reset_index()\n",
    "purchases_per_sub_category.columns=['user_id', 'sub_commodity_desc', 'purchases_per_sub_category']\n",
    "targets_lvl_2 = targets_lvl_2.merge(purchases_per_sub_category, how='left', on=['user_id', 'sub_commodity_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем новые признаки\n",
    "# покупки в каждой под-категории в денежном эквиваленте\n",
    "value_per_sub_category = data_train_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "value_per_sub_category = value_per_sub_category.groupby(['user_id', 'sub_commodity_desc'])['sales_value'].sum().reset_index()\n",
    "value_per_sub_category.columns=['user_id', 'sub_commodity_desc', 'value_per_sub_category']\n",
    "targets_lvl_2 = targets_lvl_2.merge(value_per_sub_category, how='left', on=['user_id', 'sub_commodity_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем новые признаки\n",
    "# среднее количество покупок в неделю для каждого товара\n",
    "purchases_per_week = data_train_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "purchases_per_week = purchases_per_week.groupby(['item_id', 'week_no'])['quantity'].sum().reset_index()\n",
    "purchases_per_week = purchases_per_week.groupby('item_id')['quantity'].mean().reset_index()\n",
    "purchases_per_week.columns=['item_id', 'purchases_per_week']\n",
    "targets_lvl_2 = targets_lvl_2.merge(purchases_per_week, how='left', on='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# готовим X_train и y_train\n",
    "X_train = targets_lvl_2.drop('target', axis=1)\n",
    "y_train = targets_lvl_2[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = X_train.columns[2:15].tolist()\n",
    "X_train[cat_feats] = X_train[cat_feats].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadejdaberzina/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/nadejdaberzina/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/nadejdaberzina/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:863: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt',\n",
       "               categorical_column=['manufacturer', 'department', 'brand',\n",
       "                                   'commodity_desc', 'sub_commodity_desc',\n",
       "                                   'curr_size_of_product', 'age_desc',\n",
       "                                   'marital_status_code', 'income_desc',\n",
       "                                   'homeowner_desc', 'hh_comp_desc',\n",
       "                                   'household_size_desc', 'kid_category_desc'],\n",
       "               class_weight=None, colsample_bytree=1.0, importance_type='split',\n",
       "               learning_rate=0.1, max_depth=7, min_child_samples=20,\n",
       "               min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "               n_jobs=-1, num_leaves=31, objective='binary', random_state=None,\n",
       "               reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обучаем LGBM\n",
    "lgb = LGBMClassifier(objective='binary', max_depth=7, categorical_column=cat_feats)\n",
    "lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучаем LightAutoML\n",
    "train_data = targets_lvl_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = Task('reg', loss='mse', metric='mse', greater_is_better=False)\n",
    "TIMEOUT = 300000\n",
    "N_THREADS = 4\n",
    "N_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "TARGET_NAME = 'target'\n",
    "TEST_SIZE=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = {'target': TARGET_NAME, 'drop': ['user_id, user_id']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_model = TabularAutoML(task=TASK,\n",
    "                            timeout=TIMEOUT,\n",
    "                            cpu_limit = N_THREADS,\n",
    "                            gpu_ids='all',\n",
    "                            reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n",
    "                             \n",
    "                            general_params={'use_algos': [ ['lgb_tuned', 'cb_tuned', 'cb', 'lgb'], ['lgb_tuned', 'cb'] ]},\n",
    "                             \n",
    "                            tuning_params={'max_tuning_iter': 10},\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-c0562d6b-3db4-465a-81ea-b13a4c6e622d\n",
      "INFO:optuna.study.study:Trial 0 finished with value: -0.03713762915464922 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244}. Best is trial 0 with value: -0.03713762915464922.\n",
      "INFO:optuna.study.study:Trial 1 finished with value: -0.03715186985415576 and parameters: {'feature_fraction': 0.8659969709057025, 'num_leaves': 159}. Best is trial 0 with value: -0.03713762915464922.\n",
      "INFO:optuna.study.study:Trial 2 finished with value: -0.03730823215272649 and parameters: {'feature_fraction': 0.5780093202212182, 'num_leaves': 53}. Best is trial 0 with value: -0.03713762915464922.\n",
      "INFO:optuna.study.study:Trial 3 finished with value: -0.03722653049641968 and parameters: {'feature_fraction': 0.5290418060840998, 'num_leaves': 223}. Best is trial 0 with value: -0.03713762915464922.\n",
      "INFO:optuna.study.study:Trial 4 finished with value: -0.03715940620105788 and parameters: {'feature_fraction': 0.8005575058716043, 'num_leaves': 185}. Best is trial 0 with value: -0.03713762915464922.\n",
      "INFO:optuna.study.study:Trial 5 finished with value: -0.037162814556167816 and parameters: {'feature_fraction': 0.5102922471479012, 'num_leaves': 248}. Best is trial 0 with value: -0.03713762915464922.\n",
      "INFO:optuna.study.study:Trial 6 finished with value: -0.03737127194738949 and parameters: {'feature_fraction': 0.9162213204002109, 'num_leaves': 66}. Best is trial 0 with value: -0.03713762915464922.\n",
      "INFO:optuna.study.study:Trial 7 finished with value: -0.03730807309853728 and parameters: {'feature_fraction': 0.5909124836035503, 'num_leaves': 60}. Best is trial 0 with value: -0.03713762915464922.\n",
      "INFO:optuna.study.study:Trial 8 finished with value: -0.03719264052181826 and parameters: {'feature_fraction': 0.6521211214797689, 'num_leaves': 141}. Best is trial 0 with value: -0.03713762915464922.\n",
      "INFO:optuna.study.study:Trial 9 finished with value: -0.0372367171167837 and parameters: {'feature_fraction': 0.7159725093210578, 'num_leaves': 85}. Best is trial 0 with value: -0.03713762915464922.\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-06d9efdb-41a7-42ef-8265-6b68a8298496\n",
      "WARNING:optuna.study._optimize:Trial 0 failed because of the following error: TypeError(\"fit() got an unexpected keyword argument 'log_cout'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nadejdaberzina/opt/anaconda3/lib/python3.7/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/Users/nadejdaberzina/opt/anaconda3/lib/python3.7/site-packages/lightautoml/ml_algo/tuning/optuna.py\", line 214, in objective\n",
      "    output_dataset = _ml_algo.fit_predict(train_valid_iterator=train_valid_iterator)\n",
      "  File \"/Users/nadejdaberzina/opt/anaconda3/lib/python3.7/site-packages/lightautoml/ml_algo/base.py\", line 274, in fit_predict\n",
      "    model, pred = self.fit_predict_single_fold(train, valid)\n",
      "  File \"/Users/nadejdaberzina/opt/anaconda3/lib/python3.7/site-packages/lightautoml/ml_algo/boost_cb.py\", line 310, in fit_predict_single_fold\n",
      "    model.fit(cb_train, eval_set=cb_valid, log_cout=LoggerStream(logger, verbose_eval=100))\n",
      "TypeError: fit() got an unexpected keyword argument 'log_cout'\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-6932ca06-e25b-453a-8e8a-1281b742e3ca\n",
      "INFO:optuna.study.study:Trial 0 finished with value: -0.03713762915464922 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244}. Best is trial 0 with value: -0.03713762915464922.\n",
      "INFO:optuna.study.study:Trial 1 finished with value: -0.03715186985415576 and parameters: {'feature_fraction': 0.8659969709057025, 'num_leaves': 159}. Best is trial 0 with value: -0.03713762915464922.\n",
      "INFO:optuna.study.study:Trial 2 finished with value: -0.03730823215272649 and parameters: {'feature_fraction': 0.5780093202212182, 'num_leaves': 53}. Best is trial 0 with value: -0.03713762915464922.\n",
      "INFO:optuna.study.study:Trial 3 finished with value: -0.03722653049641968 and parameters: {'feature_fraction': 0.5290418060840998, 'num_leaves': 223}. Best is trial 0 with value: -0.03713762915464922.\n",
      "INFO:optuna.study.study:Trial 4 finished with value: -0.03715940620105788 and parameters: {'feature_fraction': 0.8005575058716043, 'num_leaves': 185}. Best is trial 0 with value: -0.03713762915464922.\n",
      "INFO:optuna.study.study:Trial 5 finished with value: -0.037162814556167816 and parameters: {'feature_fraction': 0.5102922471479012, 'num_leaves': 248}. Best is trial 0 with value: -0.03713762915464922.\n",
      "INFO:optuna.study.study:Trial 6 finished with value: -0.03737127194738949 and parameters: {'feature_fraction': 0.9162213204002109, 'num_leaves': 66}. Best is trial 0 with value: -0.03713762915464922.\n",
      "INFO:optuna.study.study:Trial 7 finished with value: -0.03730807309853728 and parameters: {'feature_fraction': 0.5909124836035503, 'num_leaves': 60}. Best is trial 0 with value: -0.03713762915464922.\n"
     ]
    }
   ],
   "source": [
    "automl_pred = automl_model.fit_predict(train_data, roles = roles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Получаем рекомендации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отберем юзеров, по которым у нас есть информация из data train\n",
    "users_lvl_2_val = pd.DataFrame(data_val_lvl_2['user_id'].unique())\n",
    "users_lvl_2_val.columns = ['user_id']\n",
    "\n",
    "train_users_lvl_2 = users_lvl_2['user_id'].unique()\n",
    "users_lvl_2_val = users_lvl_2_val[users_lvl_2_val['user_id'].isin(train_users_lvl_2)]\n",
    "\n",
    "\n",
    "# создаем dataframe, куда будем сохранять рекомендации\n",
    "result_lvl_2 = data_val_lvl_2.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result_lvl_2.columns=['user_id', 'actual']\n",
    "\n",
    "result_lvl_2 = result_lvl_2[result_lvl_2['user_id'].isin(targets_lvl_2.user_id.unique()) ]\n",
    "\n",
    "result_lvl_2 = users_lvl_2_val.merge(result_lvl_2, how='left', on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем кандидатов\n",
    "users_lvl_2_val['candidates'] = users_lvl_2_val['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем dataframe для модели второго уровня с флагом купил / не купил\n",
    "s = users_lvl_2_val.apply(lambda x: pd.Series(x['candidates']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'item_id'\n",
    "\n",
    "users_lvl_2_val = users_lvl_2_val.drop('candidates', axis=1).join(s)\n",
    "\n",
    "targets_lvl_2_val = data_val_lvl_2[['user_id', 'item_id']].copy()\n",
    "\n",
    "targets_lvl_2_val = users_lvl_2_val.merge(targets_lvl_2_val, on=['user_id', 'item_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим имеющиеся данные по пользователям и товарам\n",
    "targets_lvl_2_val = targets_lvl_2_val.merge(item_features, on='item_id', how='left')\n",
    "targets_lvl_2_val = targets_lvl_2_val.merge(user_features, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем новые признаки\n",
    "# средний чек\n",
    "average_receipt = data_val_lvl_2.groupby(['user_id', 'basket_id'])['sales_value'].sum().reset_index()\n",
    "average_receipt = average_receipt.groupby('user_id')['sales_value'].mean().reset_index()\n",
    "average_receipt.columns=['user_id', 'average_receipt']\n",
    "targets_lvl_2_val = targets_lvl_2_val.merge(average_receipt, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем новые признаки\n",
    "# кол-во покупок в каждой категории\n",
    "purchases_per_category = data_val_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "purchases_per_category = purchases_per_category.groupby(['user_id', 'commodity_desc'])['quantity'].sum().reset_index()\n",
    "purchases_per_category.columns=['user_id','commodity_desc', 'purchases_per_category']\n",
    "targets_lvl_2_val = targets_lvl_2_val.merge(purchases_per_category, how='left', on=['user_id', 'commodity_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем новые признаки\n",
    "# кол-во покупок в каждой под-категории\n",
    "purchases_per_sub_category = data_val_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "purchases_per_sub_category = purchases_per_sub_category.groupby(['user_id', 'sub_commodity_desc'])['quantity'].sum().reset_index()\n",
    "purchases_per_sub_category.columns=['user_id','sub_commodity_desc', 'purchases_per_sub_category']\n",
    "targets_lvl_2_val = targets_lvl_2_val.merge(purchases_per_sub_category, how='left', on=['user_id', 'sub_commodity_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем новые признаки\n",
    "# покупки в каждой под-категории в денежном эквиваленте\n",
    "value_per_sub_category = data_val_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "value_per_sub_category = value_per_sub_category.groupby(['user_id', 'sub_commodity_desc'])['sales_value'].sum().reset_index()\n",
    "value_per_sub_category.columns=['user_id','sub_commodity_desc', 'value_per_sub_category']\n",
    "targets_lvl_2_val = targets_lvl_2_val.merge(value_per_sub_category, how='left', on=['user_id', 'sub_commodity_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем новые признаки\n",
    "# среднее количество покупок в неделю для каждого товара\n",
    "purchases_per_week = data_val_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "purchases_per_week = purchases_per_week.groupby(['item_id', 'week_no'])['quantity'].sum().reset_index()\n",
    "purchases_per_week = purchases_per_week.groupby('item_id')['quantity'].mean().reset_index()\n",
    "purchases_per_week.columns=['item_id', 'purchases_per_week']\n",
    "targets_lvl_2_val = targets_lvl_2_val.merge(purchases_per_week, how='left', on='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# готовим данные\n",
    "cat_feats = targets_lvl_2_val.columns[2:15].tolist()\n",
    "targets_lvl_2_val[cat_feats] = targets_lvl_2_val[cat_feats].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM\n",
    "val_preds = lgb.predict_proba(targets_lvl_2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lgbm', 0.617373103087389)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создаем dataframe с предсказаниями и считаем целевую метрику для модели первого уровня и модели \n",
    "\n",
    "val_preds = val_preds[:, 1]\n",
    "\n",
    "result_val = targets_lvl_2_val\n",
    "result_val['preds'] = val_preds\n",
    "\n",
    "result_val = result_val.groupby(['user_id', 'item_id'])['preds'].mean().reset_index()\n",
    "result_val = result_val.groupby('user_id').apply(lambda x: x.sort_values('preds', ascending=False).head(5).item_id.tolist())\n",
    "result_val = result_lvl_2.merge(result_val.rename('lgbm'), how='left', on='user_id')\n",
    "\n",
    "sorted(calc_metrics(result_val, precision_at_k, k=5), key=lambda precision_at_k: precision_at_k[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light AutoML\n",
    "automl_pred_val = automl_model.predict(targets_lvl_2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = automl_pred_val.data\n",
    "targets_lvl_2_val['preds_automl'] = result\n",
    "targets_lvl_2_val['preds_automl'] = abs(targets_lvl_2_val['preds_automl'])\n",
    "\n",
    "targets_lvl_2_val = targets_lvl_2_val.groupby(['user_id', 'item_id'])['preds_automl'].mean().reset_index()\n",
    "\n",
    "result_val_automl = targets_lvl_2_val.groupby('user_id').apply(lambda x: x.sort_values('preds_automl', ascending=False).head(5).item_id.tolist())\n",
    "\n",
    "result_val_automl = result_lvl_2.merge(result_val_automl.rename('automl'), how='left', on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('automl', 0.6469911041339588)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(calc_metrics(result_val_automl, precision_at_k, k=5), key=lambda precision_at_k: precision_at_k[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Добавляем рекомендации для новых пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = pd.DataFrame(data_val_lvl_2['user_id'].unique())\n",
    "recs.columns = ['user_id']\n",
    "\n",
    "old_users = result_lvl_2['user_id'].unique()\n",
    "new_users = recs[~recs['user_id'].isin(old_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity_recommendation(data, n=5):\n",
    "    \n",
    "    popular = data.groupby('item_id')['sales_value'].sum().reset_index()\n",
    "    popular.sort_values('sales_value', ascending=False, inplace=True)\n",
    "    \n",
    "    recs = popular.head(n).item_id\n",
    "    return recs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadejdaberzina/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "popular_recs = popularity_recommendation(data_train_lvl_1, n=6)\n",
    "popular_recs = popular_recs[1:]\n",
    "\n",
    "new_users['recs'] = new_users['user_id'].apply(lambda x: popular_recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Объединяем все полученные рекомендации и проверяем качество модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadejdaberzina/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4449: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "result_val_new = result_val_automl[['user_id', 'automl']]\n",
    "result_val_new.rename(columns={'automl': 'recs'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = pd.concat([result_val_new, new_users])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lvl_2 = data_val_lvl_2.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result_lvl_2.columns=['user_id', 'actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = result_lvl_2.merge(recommendations, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('recs', 0.6143351458230328)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(calc_metrics(recs, precision_at_k, k=5), key=lambda precision_at_k: precision_at_k[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат по precision@5, полученный на валидационном наборе, сопоставим с результатом, полученным на data_val_lvl_2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
